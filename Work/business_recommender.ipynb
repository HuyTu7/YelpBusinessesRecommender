{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Recommender System using Apache Spark and Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv \n",
    "import random\n",
    "import math\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = list()\n",
    "data1 = list()\n",
    "included_cols = [12, 13, 11]\n",
    "with open('../Sample Data/merged_BR3.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader, None)\n",
    "    for row in reader:\n",
    "        if row[3] in ['Huntersville']:\n",
    "            content = (int(float(row[12])), int(float(row[13])), float(row[11]))\n",
    "            content1 = (int(float(row[13])), str(row[4]))\n",
    "            data.append(tuple(content))\n",
    "            data1.append(content1)\n",
    "dataParallelized = sc.parallelize(data)\n",
    "#dataParallelized.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Splitting Data into Testing and Training Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(22, 3, 1.85), (23, 3, 2.0), (24, 3, 0.644444444444)]\n",
      "[(26, 3, 5.0), (27, 3, 4.0), (1551, 68, 5.0)]\n"
     ]
    }
   ],
   "source": [
    "#splitting the RDD into training and test datasets [.6, .4]\n",
    "training_set, testing_set = dataParallelized.randomSplit([.6,.4], 13)\n",
    "training_set.cache()\n",
    "testing_set.cache()\n",
    "\n",
    "print training_set.take(3)\n",
    "print testing_set.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score(predict, actual):\n",
    "    MSE = []\n",
    "    count = 0.0\n",
    "    for a in actual:\n",
    "        for p in predict:\n",
    "            if a[0] == p[0]:\n",
    "                #print str(p[1]) + \" \" + str(a[1])\n",
    "                count += 1\n",
    "                SE = (a[1] - p[1])**2\n",
    "                MSE.append(SE)\n",
    "    if count == 0.0:\n",
    "        return -1\n",
    "    else:\n",
    "        return sum(MSE)/count\n",
    "\n",
    "def modelEval(mod, trainData, testData):\n",
    "    test_userIDs = testData.map(lambda p: p[0]).distinct().collect()\n",
    "    #print test_userIDs\n",
    "    test_companyIDs = dataParallelized.map(lambda p: p[1]).distinct().collect()\n",
    "    #print test_companyIDs\n",
    "    trainSet = trainData.map(lambda x: (x[0], x[1])).filter(lambda x: x[0] in test_userIDs)\n",
    "    trainSet = trainSet.groupByKey().map(lambda x: (x[0], list(x[1])))\n",
    "    #print trainSet.take(3)\n",
    "    #if bid not in [y[0] for y in x[1]]\n",
    "    validationSet = trainSet.flatMap(lambda x: [(x[0],bid) for bid in test_companyIDs])\n",
    "    #print validationSet.take(3)\n",
    "    actualD = testData.map(lambda x: (x[0], (x[1], x[2]))).groupByKey()\n",
    "    actualD = actualD.map(lambda x: (x[0], list(x[1]))).collectAsMap()\n",
    "    #print actualD\n",
    "    predictD = mod.predictAll(validationSet).map(lambda x: (x[0], (x[1], x[2])))\n",
    "    predictD = predictD.groupByKey().map(lambda x: (x[0], sorted(list(x[1]), key=lambda score: score[1], reverse=True)))\n",
    "    maxList = predictD.map(lambda x: x[1][0][1])\n",
    "    minList = predictD.map(lambda x: x[1][-1][1])\n",
    "    maxVal = max(maxList.collect())\n",
    "    minVal = min(minList.collect())\n",
    "    scale = maxVal - minVal\n",
    "    predictD_scale = predictD.map(lambda x: (x[0], [(y[0],((y[1]-minVal)/scale)*6) for y in x[1]]))\n",
    "    \n",
    "    #print predictD.take(1)\n",
    "    scores = []\n",
    "    for entry in predictD_scale.collect():\n",
    "        score_pe = score(entry[1], actualD[entry[0]])\n",
    "        #print score_pe\n",
    "        if score_pe != -1:\n",
    "            scores.append(score_pe)\n",
    "    MSE_score = sum(scores)/float(len(scores))\n",
    "    RMSE_score = math.sqrt(MSE_score)\n",
    "    return RMSE_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing model for different ranks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model score for rank 2 is 3.059966\n",
      "The model score for rank 10 is 2.479931\n",
      "The model score for rank 20 is 2.851298\n"
     ]
    }
   ],
   "source": [
    "ranks = [2, 10, 20]\n",
    "for r in ranks:\n",
    "    model = ALS.trainImplicit(training_set, rank=r)\n",
    "    print \"The model score for rank %d is %f\" % (r, modelEval(model, training_set, testing_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chosing the rank of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.851298481955958"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel = ALS.trainImplicit(training_set, rank=10)\n",
    "modelEval(model, training_set, testing_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Some Business Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business 0: Bad Daddy's Burger Bar\n",
      "business 1: Red Rocks Cafe - Birkdale\n",
      "business 2: Kung Foo Noodle\n",
      "business 3: Cafe 100\n",
      "business 4: Pinky's Westside Grill\n"
     ]
    }
   ],
   "source": [
    "user = data[0][-2]\n",
    "name = list()\n",
    "for x in bestModel.recommendProducts(user, 5):\n",
    "    #print x.product\n",
    "    for line in data1:\n",
    "        if line[0] == x.product and line[1] not in name:\n",
    "            name.append(line[1])\n",
    "for i in range(len(name)):\n",
    "    print(\"business %d: %s\" % (i, name[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
